{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictingGD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PandiRaja18/Machine-Learning/blob/ML/predictingGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsawMfdOfaeh"
      },
      "source": [
        "# **Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEt91vHDfmpU"
      },
      "source": [
        "# **Pima Indians Diabetes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQcSA_Bp8PGt"
      },
      "source": [
        "PregnanciesNumber of times pregnant\n",
        "\n",
        "GlucosePlasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "BloodPressureDiastolic blood pressure (mm Hg)\n",
        "\n",
        "SkinThicknessTriceps skin fold thickness (mm)\n",
        "\n",
        "Insulin2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "BMIBody mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "DiabetesPedigreeFunctionDiabetes pedigree function\n",
        "\n",
        "AgeAge (years)\n",
        "\n",
        "OutcomeClass variable (0 or 1) 268 of 768 are 1, the others are 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9thnW8_BfWqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d484a65f-0cdd-45b2-c9af-9be65da717a9"
      },
      "source": [
        "!git clone https://github.com/deepanrajm/machine_learning.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'machine_learning'...\n",
            "remote: Enumerating objects: 70064, done.\u001b[K\n",
            "remote: Counting objects: 100% (70064/70064), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70053/70053), done.\u001b[K\n",
            "remote: Total 72556 (delta 14), reused 70052 (delta 8), pack-reused 2492\n",
            "Receiving objects: 100% (72556/72556), 121.67 MiB | 29.78 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Checking out files: 100% (3002/3002), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWilZ7H8cpE"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "#five important Algorithms\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#After 0.8 the train test split move to model selction\n",
        "#So the check the version\n",
        "if int((sklearn.__version__).split(\".\")[1]) < 18:\n",
        "\tfrom sklearn.cross_validation import train_test_split\n",
        "\n",
        "else:\n",
        "\tfrom sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ens470-8ge2"
      },
      "source": [
        "dataset = np.loadtxt(\"machine_learning/Machine_learning/1_PIMA/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "#Combine first 8 as input and last one column as output.\n",
        "#Before undergoing process we have to test it these are the first step.\n",
        "data = dataset[:,0:8] # 0 - 7 is the first 8 column\n",
        "labels = dataset[:,8] # last column output."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOWrnXLX8mc_"
      },
      "source": [
        "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(data),\n",
        "\tnp.array(labels), test_size=0.25, random_state=42)\n",
        "#First 25% (0.25) of the data set is for the testing \n",
        "#next 75% of the dataset is for the training\n",
        "#we use a random set 42 so that everyone get their own and same ouput."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OE3Aqpw87ts"
      },
      "source": [
        "# **Decision Trees**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZFCXtOXkgqV"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1x5droBZwH8RB4nqE77owjcb3m_aOBgvU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VaRT6hPpPG5"
      },
      "source": [
        "**splitter{“best”, “random”}, default=”best”**\n",
        "\n",
        "The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
        "\n",
        "**max_featuresint, float or {“auto”, “sqrt”, “log2”}, default=None**\n",
        "\n",
        "The number of features to consider when looking for the best split:\n",
        "\n",
        "If int, then consider max_features features at each split.\n",
        "\n",
        "If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.\n",
        "\n",
        "If “auto”, then max_features=sqrt(n_features).\n",
        "\n",
        "If “sqrt”, then max_features=sqrt(n_features).\n",
        "\n",
        "If “log2”, then max_features=log2(n_features).\n",
        "\n",
        "If None, then max_features=n_features.\n",
        "\n",
        "*Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9eVrLOt85uD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4084c28c-ed01-43af-d5d8-b93c0251020d"
      },
      "source": [
        "#splitter = best, random , max_features = int, auto, log, none\n",
        "model = DecisionTreeClassifier(random_state=84,splitter='best', max_features=8)\n",
        "#It is not needed to use all the three parameter we may use random_state alone.\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels) #Use to create by model\n",
        "#The above to lines are used t0 create our data model.\n",
        "#Our algorithm is done\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "#Predicting the model for our dataset\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))\n",
        "#In output :\n",
        "  # Support is nothing but how many data is required to give this output\n",
        "  # The other three is our predition\n",
        "  # f1 is the cummulative average of the precision and recall\n",
        "  # precision is (true positve) how many times my model find the right percent i.e.,0 \n",
        "  # Recall is (true negative) how many times my model find the wrong percent corectly i.e.,1 "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.69      0.74       123\n",
            "         1.0       0.55      0.68      0.61        69\n",
            "\n",
            "    accuracy                           0.69       192\n",
            "   macro avg       0.67      0.69      0.67       192\n",
            "weighted avg       0.71      0.69      0.69       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMOStwpD9FGs"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9cX7u2p-Is"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1JRk2b-NbpsTbRALKDzIJngfUjOZvj8gk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKdOjYnG9J-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1183628f-da51-4c8a-dcee-4ed00ae67f9f"
      },
      "source": [
        "# n-estimate is the number of trees used for this particular model\n",
        "# 10 diff trees and 10 diff output\n",
        "# To many trees may be complex. \n",
        "# The feature 'auto' select the feature automatically when to split and when not to..\n",
        "model = RandomForestClassifier(n_estimators=10, random_state=42,max_features=\"auto\")\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))\n",
        "\n",
        "#In output :\n",
        "   #In support class 0 has 123 and class 1 has 69\n",
        "   #The data getting is more in one class might be problem.\n",
        "   #But we get a decent accuracy.\n",
        "   # From 10 - 12 (n_estimators) the accuracy is decent"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.79      0.80       123\n",
            "         1.0       0.63      0.65      0.64        69\n",
            "\n",
            "    accuracy                           0.74       192\n",
            "   macro avg       0.72      0.72      0.72       192\n",
            "weighted avg       0.74      0.74      0.74       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tddo9sY9Nn4"
      },
      "source": [
        "# **KNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZhe0Tj4sHYX"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=12O0KRMCL0aO9wIebmPoAmfQdHgLBs4Gt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmi2jHsB9Oo2"
      },
      "source": [
        "#weights = uniform, weights\n",
        "model = KNeighborsClassifier(n_neighbors=9)\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWi5XPe39RIr"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U_5BRZGv_DT"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1I48gEU3IMSFRriv-Uv2qVXy1bJqIrBaz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydWqVAuTwFxt"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1qENQ38k3MwqjAyjc19j-zEvbEIfvYI9Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ll2F_6hwzaz"
      },
      "source": [
        "**The C parameter** trades off correct classification of training examples against maximization of the decision function’s margin. For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words``C`` behaves as a regularization parameter in the SVM\n",
        "\n",
        "\n",
        "**The gamma parameter** defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF3IdqNn9T0Q"
      },
      "source": [
        "#kernel='rbf', linear, poly, C=1, gamma='scale'\n",
        "model = SVC(kernel=\"linear\",C=1)\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njb9Sy3N9C2G"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HO6v_XqyjSp"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1N2HJHTUlzSj6jqD8b61pYbCYo_rhXaYS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-4fRG-2yS0F"
      },
      "source": [
        "**solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’**\n",
        "Algorithm to use in the optimization problem.\n",
        "\n",
        "For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
        "\n",
        "For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
        "\n",
        "‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
        "\n",
        "‘liblinear’ and ‘saga’ also handle L1 penalty\n",
        "\n",
        "‘saga’ also supports ‘elasticnet’ penalty\n",
        "\n",
        "‘liblinear’ does not support setting penalty='none'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOsdLirbyM2Y"
      },
      "source": [
        "**penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’**\n",
        "\n",
        "Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JCc9ND1fryj"
      },
      "source": [
        "#penality = l1,l2, elasticnet\n",
        "#solver = liblinear, sag, saga, lbfgs, newton-cg\n",
        "#max-iter = 100\n",
        "\n",
        "model = LogisticRegression(max_iter=15)#,solver = 'sag')\n",
        "\n",
        "#penalty='l1',solver=\"saga\",max_iter=100\n",
        "\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}